# **低能耗的脉冲视觉模型研究**

本任务旨在推动脉冲神经网络（SNN）与视觉Mamba模型的交叉创新，结合SNN的低能耗特性和Mamba的长序列建模优势，探索新型高效混合架构。

QKFormer文件夹对应于子任务1，Vim文件夹对应于子任务2，其中包含代码以及详细的运行指南。

## 子任务1：脉冲神经网络模型复现与优化

本实验旨在复现**QKFormer**模型在图像分类视觉任务中的基准性能，通过在多个标准数据集上训练和测试模型，验证其作为脉冲神经网络（SNN）新模型的有效性和稳定性。QKFormer 是近年来提出的层次化脉冲 Transformer 模型，采用了新颖的 Q-K 注意力机制，直接训练即可在大型数据集上取得优异成绩。在ImageNet-1K数据集上，QKFormer 模型首次将直接训练的 SNN 模型 Top-1 准确率提升到85.65%，大幅超越先前 SNN 模型的记录。本实验的目标是在较小规模的数据集（CIFAR-10、CIFAR-100 和 Tiny ImageNet）上对 QKFormer 进行基础复现，通过严格遵循论文和开源实现的配置，获得模型准确率和训练耗时等指标，并分析模型在不同数据集上的表现差异。这为后续可能的优化改进提供基准参考。

## 子任务2：视觉Mamba模型复现与改进

Vision Mamba（简称 Vim）是一种新颖的视觉骨干网络架构，使用**双向** **Mamba** **状态空间模型块**（SSM）取代了传统视觉Transformer中的自注意力机制。该模型在ImageNet图像分类等任务上取得了可观性能，同时显著提升了推理速度和内存效率。例如，与DeiT-Tiny相比，Vim-Tiny在高分辨率图像上推理速度快约2.8倍，显存占用减少了86.8%。本实验旨在**复现** **Vision Mamba Tiny****模型在图像分类任务上的基本训练过程和结果**，以验证其在较小规模数据集上的有效性，并加深对SSM架构的理解。通过在ImageNet-1K数据集子集上训练Vim-Tiny模型，我们希望观察模型的收敛情况和分类性能，确认其在较少类别数据上仍能取得良好效果，并与文献中的基准结果进行对比。实验还将评估该模型的训练效率和资源占用情况，以反思SSM架构在实际应用中的优势和可能的局限。

## 模型权重文件

网盘链接：https://pan.baidu.com/s/1aTuazjWyUU7Mu4ofSZlBNw 提取码: 0713

模型权重文件\QKFormer\cf10_model_best.pth.tar：在CIFAR-10数据集上训练的QKFormer的最佳模型权重

模型权重文件\QKFormer\cf100_model_best.pth.tar：在CIFAR-100数据集上训练的QKFormer的最佳模型权重

模型权重文件\Vim\checkpoint.pth：Vim的模型权重

模型权重文件\Vim\best_checkpoint.pth：Vim的最佳模型权重
